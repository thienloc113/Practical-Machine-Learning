## Project
## Loading libraries
library(ggplot2); library(caret); library(randomForest); library(rpart); library(rpart.plot)
##Loading data and pre-processing
training <- read.csv("pml-training.csv", na.strings = c("NA","#DIV/0!", ""))
testing <- read.csv("pml-testing.csv", na.strings = c("NA","#DIV/0!", ""))
View(training)
View(testing)
str(training)
str(testing)
View(training)
#Then we delete columns which are irrelevant, and have little predicting power, follow me these are columns from 1 to seven
trainset <-training[, -c(1:7)]
testset <- test[, -c(1:7)]
testset <- testing[, -c(1:7)]
trainset$classe
trainset$class
trainset$clas
trainset$a
trainset$clasw
inTrain <- createDataPartition(y=trainset$classe, p=0.75, list=FALSE)
train <- trainset[inTrain, ]
validt <- trainset[-inTrain, ]
valid <- trainset[-inTrain, ]
table(train$classe)
## Building prediction algorithms
#We will investigate the classification trees and random forests to predict the outcome.
#1. classification trees
model1 <- rpart(classe ~ ., data=train, method="class")
library(ggplot2); library(caret); library(randomForest); library(rpart); library(rpart.plot)
model1 <- rpart(classe ~ ., data=train, method="class")
prediction1 <- predict(model1, valid, type = "class")
confusionMatrix(prediction1, valid$classe)
prediction1
View(valid)
valid$classe
confusionMatrix(prediction1, as.factor(valid$classe))
#If we plot the classification trees
rpart.plot(model1, main="Classification Tree", extra=102, under=TRUE, faclen=0)
#If we plot the classification trees
rpart.plot(model1, main="Classification Tree", under=TRUE, faclen=0)
, extra=102
#If we plot the classification trees
rpart.plot(model1, main="Classification Tree", extra=102, faclen=0)
#If we plot the classification trees
rpart.plot(model1, main="Classification Tree", extra=102)
#If we plot the classification trees
fancyRpartPlot(fit_rpart$finalModel)
library(rattle)
install.packages("rattle")
library(rattle)
#If we plot the classification trees
fancyRpartPlot(fit_rpart$finalModel)
fancyRpartPlot(prediction1)
fancyRpartPlot(model1)
#If we plot the classification trees
rpart.plot(model1, main="Classification Tree", extra=102)
#From the confusion matrix, the accuracy rate is 0.7445
#2. Random forest
model2 <- randomForest(classe ~. , data=TrainTrainingSet, method="class")
prediction2 <- predict(model2, valid, type = "class")
#From the confusion matrix, the accuracy rate is 0.7445
#2. Random forest
model2 <- randomForest(classe ~. , data=train, method="class")
prediction2 <- predict(model2, valid, type = "class")
#From the confusion matrix, the accuracy rate is 0.7445
#2. Random forest
model2 <- randomForest(classe ~. , data=train, method="class")
#From the confusion matrix, the accuracy rate is 0.7445
#2. Random forest
model2 <- randomForest(classe ~. , data=train, method="class")
